<!DOCTYPE html>

<html lang="en-us">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <link rel="shortcut icon" href="./images/favicon.ico" />
    <title>Shengke Xue</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="theme-color" content="#157878">
    <link rel="stylesheet" href="./index_files/normalize.css">
    <link href="./index_files/css" rel="stylesheet" type="text/css">
    <link rel="stylesheet" href="./index_files/cayman-researches.css">
  <style id="__web-inspector-hide-shortcut-style__" type="text/css">
.__web-inspector-hide-shortcut__, .__web-inspector-hide-shortcut__ *, .__web-inspector-hidebefore-shortcut__::before, .__web-inspector-hideafter-shortcut__::after
{
    visibility: hidden !important;
}
</style>
	<script type="text/x-mathjax-config">
		MathJax.Hub.Config({
		tex2jax: {
			skipTags: ['script', 'noscript', 'style', 'textarea', 'pre']
		}
		});
		MathJax.Hub.Queue(function() {
			var all = MathJax.Hub.getAllJax(), i;
			for(i = 0; i < all.length; i += 1) {
				all[i].SourceElement().parentNode.className += ' has-jax';
			}
		});
		MathJax.Hub.Config({
			TeX: { equationNumbers: { autoNumber: "AMS" } }
		});
	</script>      
	<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"> </script>
</head>

<body>
<section class="page-header">
    <table width="100%" border="0">
    <tr>
        <td>
    		<a style="visibility:hidden" href="./index_CN.html" class="btn" title="turn to the Chinese page">&nbsp;中&nbsp;&nbsp;文&nbsp;</a>
    		<a style="visibility:hidden" href="./index.html" class="btn" title="turn to the English page">English</a>
    		<a style="visibility:hidden" class="btn" title="">Invisible</a>
    	</td>  
    	<td align="right" valign="top">
        	<img src="images/head_rect.png" title="Shengke Xue" alt="" width="200" style="max-width:100%;" data-canonical-src="https://placekitten.com/g/300/200/">
    	</td>
        <td align="center">
            <h1 class="project-name">
            Shengke Xue
            </h1>
            <h2 class="project-tagline">
            To be an average successful young scientist. —— Mu-ming Poo lab's rules
            </h2>
        <td align="left" valign="top">
 	       <a href="https://sites.google.com/view/shengkexue" target="_blank"><img src="images/avator.png" title="Shengke Xue" alt="" width="170" style="max-width:100%;" data-canonical-src="https://placekitten.com/g/300/200/"></a>
        </td>
        <td align="right" valign="top">
            <a style="visibility:hidden" class="btn" title="">Invisible</a>
        	<a style="visibility:hidden" href="./index_CN.html" class="btn" title="turn to the Chinese page">&nbsp;中&nbsp;&nbsp;文&nbsp;</a>
        	<a href="./index.html" class="btn" title="back to the home page">&nbsp;Home&nbsp;</a>
        </td>
    </tr>
    </table>

    <a href="https://github.com/xueshengke" target="_blank"><img src="images/github.png" title="GitHub" width="60" height="60"></a>
    &emsp;&emsp;
    <a href="http://blog.csdn.net/xueshengke" target="_blank"><img src="images/csdn.png" title="CSDN" width="60" height="60"></a>
    &emsp;&emsp;
    <a href="https://scholar.google.com/citations?user=n-Z8kN8AAAAJ&hl=zh-CN" target="_blank"><img src="images/scholar.png" title="Google Scholar" width="60" height="60"></a>
    &emsp;&emsp;
    <a href="https://ieee-collabratec.ieee.org/app/p/ShengkeXue" target="_blank"><img src="images/collabratec.png" title="IEEE Collabratec" width="60" height="60"></a>
    &emsp;&emsp;
    <a href="http://orcid.org/0000-0002-9219-488X" target="_blank"><img src="images/orcid.png" title="ORCID" width="60" height="60"></a>    
    &emsp;&emsp;
    <a href="https://www.mendeley.com/profiles/shengke-xue/" target="_blank"><img src="images/mendeley.png" title="Mendeley" width="60" height="60"></a>    
    &emsp;&emsp;
    <!--<img src="images/primalab_logo.png" title="PRIMA Lab" width="60" height="60"></a>-->   
</section>

<section class="main-content">

    
    <h1>
      <a id="Researches" class="anchor" aria-hidden="true"><span class="octicon octicon-link"></span></a>
    <img href src="images/icons/研究.png" width="25" height="25" align="baseline">
      Researches
    </h1>

	<div align="center"><img src="./images/papers/WRANSR_1.png" align="middle" width="800" title="Fig. 1"></div>
	<p><strong>Fig. 1</strong>&emsp;Overall structure of our Wavelet-based residual attention network.
	</p>
	
	<div align="center"><img src="./images/papers/WRANSR_block.png" align="middle" width="800" title="Fig. 2"></div>
	<p><strong>Fig. 2</strong>&emsp;Multi-kernel convolutional layer, channel attention module. and spatial attention module. 
	</p>
	
    [1] &nbsp; <strong>S. Xue</strong>, W. Qiu, F. Liu, and X. Jin. Wavelet-based residual attention network for image super-resolution. <em>Neurocomputing</em>, accepted, <strong>2019</strong>. <a href="https://doi.org/10.1016/j.neucom.2019.11.044" target="_blank">DOI 10.1016/j.neucom.2019.11.044</a></li>

<hr>

	<div align="center"><img src="./images/papers/IFNNSR_1.png" align="middle" width="800" title="Fig. 3"></div>
	<p><strong>Fig. 3</strong>&emsp;Structure of our proposed network with one block.
	</p>
	
	<div align="center"><img src="./images/papers/IFNNSR_2.png" align="middle" width="800" title="Fig. 4"></div>
	<p><strong>Fig. 4</strong>&emsp;Overall structure of our proposed improved frequency domain neural network. 
	</p>
	
    [2] &nbsp; <strong>S. Xue</strong>, W. Qiu, F. Liu, and X. Jin. Faster super-resolution by improved frequency domain neural networks. <em>Singal, Image and Video Processing</em>, in press, <strong>2019</strong>. <a href="https://doi.org/10.1007/s11760-019-01548-8" target="_blank">DOI 10.1007/s11760-019-01548-8</a>

<hr>

		<div align="center"><img src="./images/papers/t-SVD.png" align="middle" width="600" title="Fig. 5"></div>
	<p><strong>Fig. 5</strong>&emsp;Illustration of the t-SVD of an \(n_1 \times n_2 \times n_3\) tensor, i.e., \(\mathcal{A} = \mathcal{U} * \mathcal{S} * \mathcal{V}^{\text{T}}\). Our tensor nuclear norm \(\|\mathcal{A}\|_*\) is defined as the sum of singular values of all frontal slices of the f-diagonal \(\mathcal{S}\), i.e.,	\( \|\mathcal{A}\|_* \triangleq \text{tr}(\mathcal{S}) = \sum_{i=1}^{n_3} \text{tr}({S}^{(i)}) =  \text{tr}(\bar{{S}}^{(1)}) = \|\bar{{A}}^{(1)}\|_*\). Note that our tensor nuclear norm becomes standard matrix nuclear norm when \(n_3 = 1\). Thus, our tensor nuclear norm can be considered as a direct extension from the matrix case to the tensor case. 
	</p>

    \begin{equation} \label{eq:tnnr_with_max}
    \begin{aligned}
    \min_{\mathcal{X}} \ \ & \|\mathcal{X}\|_* - \max_{\substack{\mathcal{A}_\ell * \mathcal{A}_\ell^\text{T} = \mathcal{I}, \\ \mathcal{B}_\ell * \mathcal{B}_\ell^\text{T} = \mathcal{I}}} \text{tr}(\mathcal{A}_\ell * \mathcal{X} * \mathcal{B}_\ell^\text{T}) \\
    \text{s.t.} \, \ \  & \  \mathcal{X}_{{\Omega}} = \mathcal{M}_{{\Omega}} .
    \end{aligned}
    \end{equation}
    
    [3] &nbsp; <strong>S. Xue</strong>, W. Qiu, F. Liu, and X. Jin. Low-rank tensor completion by truncated nuclear norm regularization. 24th International Conference on Pattern Recognition, Beijing, <strong>2018</strong>, p.2600-2605. <a href="https://ieeexplore.ieee.org/abstract/document/8546008" target="_blank">DOI 10.1109/ICPR.2018.8546008</a>

<hr>

	<div align="center"><img src="./images/papers/Xue2017Robust.png" align="middle" width="500" height="400" title="Fig. 6"></div>
	<p><strong>Fig. 6</strong>&emsp;An example of CPLRR architecture with 3 classes. In a classwise
	  manner, our approach jointly aligns images and learns a nonlinear
	  projective function. It separates out the low-rank components with the
	  domain transformations and projects the original corrupted images to
  the low-rank representations of the exact categories.</p>

    \begin{equation}
    \begin{aligned} \label{eq:CPLRR}
    \min_{A,E,\varDelta\tau,W,B} \quad &\sum_{i=1}^{N}||A_i||_* + \lambda ||E_i||_1  \\
    \mathrm{s.t.} \, \quad \quad & D_i \circ \tau_i + \sum_{k=1}^{n_i} J_{ik} \varDelta \tau_i \varepsilon_k \varepsilon_k^{\mathrm{T}} = A_i + E_i,  \\
    & A_i - f(W_iD_i + B_i) = 0, \ \ i = 1,2,\cdots,N, \\
    & \! - \sum_{j=1}^{N} ||A_i - f(W_iD_j + B_i)||_\mathrm{F}^2 < \xi,\ j \neq i . \\
    \end{aligned}
    \end{equation}

	[4] &nbsp; <strong>S. Xue</strong> and X. Jin. Robust classwise and projective low-rank representation for image classification. <em>Signal, Image and Video Processing</em>, <strong>2018</strong>, 12(1):107-115. <a href="https://doi.org/10.1007/s11760-017-1136-1" target="_blank">DOI 10.1007/s11760-017-1136-1</a>

<hr>

<footer class="site-footer">

    <span class="site-footer-owner">This page is maintained by <a href="#">Shengke Xue</a>.</span>
	<span class="site-footer-credits">Created on Wednesday, 30-Nov-2016. Last modified on </span>
	<!-- #BeginDate format:wfcEn2 -->Saturday, 07-Dec-2019<!-- #EndDate -->.
  </footer>
    
</section>

</body>
</html>